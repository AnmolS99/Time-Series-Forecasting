model_seq72_epochs7_batch32

* 72 sequence length, and 7 epochs. Seems to be to short of a sequence and too few epochs. Model undertrained.

Remark: val_X did not have all one-hot encodings of month (since it only spans from march to june, this was fixed afterwards)
