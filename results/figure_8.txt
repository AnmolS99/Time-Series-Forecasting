model_seq72_epochs7_batch32

* Everything same as before, changed LSTM layers to GRU layers
* Changed so that "flow" has correct sign

model = tf.keras.Sequential()
        model.add(tf.keras.layers.InputLayer((self.seq_len, self.num_feat)))
        model.add(tf.keras.layers.GRU(64, return_sequences=True))
        model.add(tf.keras.layers.Dropout(0.20))
        model.add(tf.keras.layers.GRU(64, return_sequences=False))
        model.add(tf.keras.layers.Dropout(0.20))
        model.add(tf.keras.layers.Dense(32, activation="relu"))
        model.add(tf.keras.layers.Dense(1, activation="linear"))
        model.compile(loss=tf.keras.losses.MeanSquaredError(),
                      optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001))

* Results: Worse than before (compared to figure_4)